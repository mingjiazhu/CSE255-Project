{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZbDwaeIZ6pp",
        "outputId": "f2fda471-cb20-4102-94d6-aa3b5db0d03c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6R0HW6LZi8u"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0vdlsNTZ6Wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77344037-f929-4adf-cbc5-049ca99deff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-9FRd9ojXor"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT = \"/content/drive/My Drive/dataset/\"\n",
        "df = pd.read_csv(DATA_ROOT+'toxic_classification_preprocessed.csv',names = ['target','comment_text','preprocessed_text'], skiprows = 1)\n",
        "#df = df.dropna(axis = 0, how = 'any')\n",
        "train = df.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
        "test = df.head(10000)\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = dataframe\n",
        "        self.texts = self.data.comment_text\n",
        "        self.labels = self.data.target\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        review = self.texts[idx]\n",
        "        sentiment = self.labels[idx]\n",
        "        return {'text': review, 'sentiment': sentiment}\n",
        "\n",
        "\n",
        "train_dataset = ToxicDataset(train)\n",
        "test_dataset = ToxicDataset(test)\n",
        "\n",
        "# class ToxicDataset(Dataset):\n",
        "#     def __init__(self, csv_file):\n",
        "#         DATA_ROOT = \"/content/drive/My Drive/dataset/\"\n",
        "#         self.data = pd.read_csv(DATA_ROOT+csv_file,names = ['target','comment_text','preprocessed_text'], skiprows = 1)\n",
        "#         self.data = self.data.dropna(axis = 0, how = 'any')\n",
        "#         self.data = self.data.sample(frac=0.001, random_state=42).reset_index(drop=True)\n",
        "#         self.texts = self.data.preprocessed_text\n",
        "#         self.labels = self.data.target\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         review = self.texts[idx]\n",
        "#         sentiment = self.labels[idx]\n",
        "#         return {'text': review, 'sentiment': sentiment}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.iloc[139]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxEZXcXAHtLw",
        "outputId": "ecd93b68-fcab-42bd-dd78-91a120d4982e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target                                                               0\n",
              "comment_text         I'm wondering why the \"parent\" went directly t...\n",
              "preprocessed_text    wonder parent went direct ww instead email tea...\n",
              "Name: 139, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.iloc[140]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZHBeFRmHx7x",
        "outputId": "22bd293f-31cd-4dee-d4c3-1c61119fcc58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target                     0\n",
              "comment_text         Me too!\n",
              "preprocessed_text        NaN\n",
              "Name: 140, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kikwkCYchN4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0579c0a4-2db3-4825-f9d4-4a9b839a5341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dap3l_IT9F3r",
        "outputId": "3dd440f5-634c-417d-a610-3a6a8eedd482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MDIWYDshXD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9bf31f3-f482-4bf4-84eb-758596c32a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Length: 180487\n",
            "Test Dataset Length: 10000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train Dataset Length: {len(train_dataset)}\")\n",
        "print(f\"Test Dataset Length: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YWvLTOxhe1C"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN52yXo_he7B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1632ff36-8963-4f83-f9ae-5c0d41c944fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end:  0\n",
            "end:  1\n",
            "end:  2\n",
            "end:  3\n",
            "end:  4\n",
            "end:  5\n",
            "end:  6\n",
            "end:  7\n",
            "end:  8\n",
            "end:  9\n",
            "end:  10\n",
            "end:  11\n",
            "end:  12\n",
            "end:  13\n",
            "end:  14\n",
            "end:  15\n",
            "end:  16\n",
            "end:  17\n",
            "end:  18\n",
            "end:  19\n",
            "end:  20\n",
            "end:  21\n",
            "end:  22\n",
            "end:  23\n",
            "end:  24\n",
            "end:  25\n",
            "end:  26\n",
            "end:  27\n",
            "end:  28\n",
            "end:  29\n",
            "end:  30\n",
            "end:  31\n",
            "end:  32\n",
            "end:  33\n",
            "end:  34\n",
            "end:  35\n",
            "end:  36\n",
            "end:  37\n",
            "end:  38\n",
            "end:  39\n",
            "end:  40\n",
            "end:  41\n",
            "end:  42\n",
            "end:  43\n",
            "end:  44\n",
            "end:  45\n",
            "end:  46\n",
            "end:  47\n",
            "end:  48\n",
            "end:  49\n",
            "end:  50\n",
            "end:  51\n",
            "end:  52\n",
            "end:  53\n",
            "end:  54\n",
            "end:  55\n",
            "end:  56\n",
            "end:  57\n",
            "end:  58\n",
            "end:  59\n",
            "end:  60\n",
            "end:  61\n",
            "end:  62\n",
            "end:  63\n",
            "end:  64\n",
            "end:  65\n",
            "end:  66\n",
            "end:  67\n",
            "end:  68\n",
            "end:  69\n",
            "end:  70\n",
            "end:  71\n",
            "end:  72\n",
            "end:  73\n",
            "end:  74\n",
            "end:  75\n",
            "end:  76\n",
            "end:  77\n",
            "end:  78\n",
            "end:  79\n",
            "end:  80\n",
            "end:  81\n",
            "end:  82\n",
            "end:  83\n",
            "end:  84\n",
            "end:  85\n",
            "end:  86\n",
            "end:  87\n",
            "end:  88\n",
            "end:  89\n",
            "end:  90\n",
            "end:  91\n",
            "end:  92\n",
            "end:  93\n",
            "end:  94\n",
            "end:  95\n",
            "end:  96\n",
            "end:  97\n",
            "end:  98\n",
            "end:  99\n",
            "end:  100\n",
            "end:  101\n",
            "end:  102\n",
            "end:  103\n",
            "end:  104\n",
            "end:  105\n",
            "end:  106\n",
            "end:  107\n",
            "end:  108\n",
            "end:  109\n",
            "end:  110\n",
            "end:  111\n",
            "end:  112\n",
            "end:  113\n",
            "end:  114\n",
            "end:  115\n",
            "end:  116\n",
            "end:  117\n",
            "end:  118\n",
            "end:  119\n",
            "end:  120\n",
            "end:  121\n",
            "end:  122\n",
            "end:  123\n",
            "end:  124\n",
            "end:  125\n",
            "end:  126\n",
            "end:  127\n",
            "end:  128\n",
            "end:  129\n",
            "end:  130\n",
            "end:  131\n",
            "end:  132\n",
            "end:  133\n",
            "end:  134\n",
            "end:  135\n",
            "end:  136\n",
            "end:  137\n",
            "end:  138\n",
            "end:  139\n",
            "end:  140\n",
            "end:  141\n",
            "end:  142\n",
            "end:  143\n",
            "end:  144\n",
            "end:  145\n",
            "end:  146\n",
            "end:  147\n",
            "end:  148\n",
            "end:  149\n",
            "end:  150\n",
            "end:  151\n",
            "end:  152\n",
            "end:  153\n",
            "end:  154\n",
            "end:  155\n",
            "end:  156\n",
            "end:  157\n",
            "end:  158\n",
            "end:  159\n",
            "end:  160\n",
            "end:  161\n",
            "end:  162\n",
            "end:  163\n",
            "end:  164\n",
            "end:  165\n",
            "end:  166\n",
            "end:  167\n",
            "end:  168\n",
            "end:  169\n",
            "end:  170\n",
            "end:  171\n",
            "end:  172\n",
            "end:  173\n",
            "end:  174\n",
            "end:  175\n",
            "end:  176\n",
            "end:  177\n",
            "end:  178\n",
            "end:  179\n",
            "end:  180\n",
            "end:  181\n",
            "end:  182\n",
            "end:  183\n",
            "end:  184\n",
            "end:  185\n",
            "end:  186\n",
            "end:  187\n",
            "end:  188\n",
            "end:  189\n",
            "end:  190\n",
            "end:  191\n",
            "end:  192\n",
            "end:  193\n",
            "end:  194\n",
            "end:  195\n",
            "end:  196\n",
            "end:  197\n",
            "end:  198\n",
            "end:  199\n",
            "end:  200\n",
            "end:  201\n",
            "end:  202\n",
            "end:  203\n",
            "end:  204\n",
            "end:  205\n",
            "end:  206\n",
            "end:  207\n",
            "end:  208\n",
            "end:  209\n",
            "end:  210\n",
            "end:  211\n",
            "end:  212\n",
            "end:  213\n",
            "end:  214\n",
            "end:  215\n",
            "end:  216\n",
            "end:  217\n",
            "end:  218\n",
            "end:  219\n",
            "end:  220\n",
            "end:  221\n",
            "end:  222\n",
            "end:  223\n",
            "end:  224\n",
            "end:  225\n",
            "end:  226\n",
            "end:  227\n",
            "end:  228\n",
            "end:  229\n",
            "end:  230\n",
            "end:  231\n",
            "end:  232\n",
            "end:  233\n",
            "end:  234\n",
            "end:  235\n",
            "end:  236\n",
            "end:  237\n",
            "end:  238\n",
            "end:  239\n",
            "end:  240\n",
            "end:  241\n",
            "end:  242\n",
            "end:  243\n",
            "end:  244\n",
            "end:  245\n",
            "end:  246\n",
            "end:  247\n",
            "end:  248\n",
            "end:  249\n",
            "end:  250\n",
            "end:  251\n",
            "end:  252\n",
            "end:  253\n",
            "end:  254\n",
            "end:  255\n",
            "end:  256\n",
            "end:  257\n",
            "end:  258\n",
            "end:  259\n",
            "end:  260\n",
            "end:  261\n",
            "end:  262\n",
            "end:  263\n",
            "end:  264\n",
            "end:  265\n",
            "end:  266\n",
            "end:  267\n",
            "end:  268\n",
            "end:  269\n",
            "end:  270\n",
            "end:  271\n",
            "end:  272\n",
            "end:  273\n",
            "end:  274\n",
            "end:  275\n",
            "end:  276\n",
            "end:  277\n",
            "end:  278\n",
            "end:  279\n",
            "end:  280\n",
            "end:  281\n",
            "end:  282\n",
            "end:  283\n",
            "end:  284\n",
            "end:  285\n",
            "end:  286\n",
            "end:  287\n",
            "end:  288\n",
            "end:  289\n",
            "end:  290\n",
            "end:  291\n",
            "end:  292\n",
            "end:  293\n",
            "end:  294\n",
            "end:  295\n",
            "end:  296\n",
            "end:  297\n",
            "end:  298\n",
            "end:  299\n",
            "end:  300\n",
            "end:  301\n",
            "end:  302\n",
            "end:  303\n",
            "end:  304\n",
            "end:  305\n",
            "end:  306\n",
            "end:  307\n",
            "end:  308\n",
            "end:  309\n",
            "end:  310\n",
            "end:  311\n",
            "end:  312\n",
            "end:  313\n",
            "end:  314\n",
            "end:  315\n",
            "end:  316\n",
            "end:  317\n",
            "end:  318\n",
            "end:  319\n",
            "end:  320\n",
            "end:  321\n",
            "end:  322\n",
            "end:  323\n",
            "end:  324\n",
            "end:  325\n",
            "end:  326\n",
            "end:  327\n",
            "end:  328\n",
            "end:  329\n",
            "end:  330\n",
            "end:  331\n",
            "end:  332\n",
            "end:  333\n",
            "end:  334\n",
            "end:  335\n",
            "end:  336\n",
            "end:  337\n",
            "end:  338\n",
            "end:  339\n",
            "end:  340\n",
            "end:  341\n",
            "end:  342\n",
            "end:  343\n",
            "end:  344\n",
            "end:  345\n",
            "end:  346\n",
            "end:  347\n",
            "end:  348\n",
            "end:  349\n",
            "end:  350\n",
            "end:  351\n",
            "end:  352\n",
            "end:  353\n",
            "end:  354\n",
            "end:  355\n",
            "end:  356\n",
            "end:  357\n",
            "end:  358\n",
            "end:  359\n",
            "end:  360\n",
            "end:  361\n",
            "end:  362\n",
            "end:  363\n",
            "end:  364\n",
            "end:  365\n",
            "end:  366\n",
            "end:  367\n",
            "end:  368\n",
            "end:  369\n",
            "end:  370\n",
            "end:  371\n",
            "end:  372\n",
            "end:  373\n",
            "end:  374\n",
            "end:  375\n",
            "end:  376\n",
            "end:  377\n",
            "end:  378\n",
            "end:  379\n",
            "end:  380\n",
            "end:  381\n",
            "end:  382\n",
            "end:  383\n",
            "end:  384\n",
            "end:  385\n",
            "end:  386\n",
            "end:  387\n",
            "end:  388\n",
            "end:  389\n",
            "end:  390\n",
            "end:  391\n",
            "end:  392\n",
            "end:  393\n",
            "end:  394\n",
            "end:  395\n",
            "end:  396\n",
            "end:  397\n",
            "end:  398\n",
            "end:  399\n",
            "end:  400\n",
            "end:  401\n",
            "end:  402\n",
            "end:  403\n",
            "end:  404\n",
            "end:  405\n",
            "end:  406\n",
            "end:  407\n",
            "end:  408\n",
            "end:  409\n",
            "end:  410\n",
            "end:  411\n",
            "end:  412\n",
            "end:  413\n",
            "end:  414\n",
            "end:  415\n",
            "end:  416\n",
            "end:  417\n",
            "end:  418\n",
            "end:  419\n",
            "end:  420\n",
            "end:  421\n",
            "end:  422\n",
            "end:  423\n",
            "end:  424\n",
            "end:  425\n",
            "end:  426\n",
            "end:  427\n",
            "end:  428\n",
            "end:  429\n",
            "end:  430\n",
            "end:  431\n",
            "end:  432\n",
            "end:  433\n",
            "end:  434\n",
            "end:  435\n",
            "end:  436\n",
            "end:  437\n",
            "end:  438\n",
            "end:  439\n",
            "end:  440\n",
            "end:  441\n",
            "end:  442\n",
            "end:  443\n",
            "end:  444\n",
            "end:  445\n",
            "end:  446\n",
            "end:  447\n",
            "end:  448\n",
            "end:  449\n",
            "end:  450\n",
            "end:  451\n",
            "end:  452\n",
            "end:  453\n",
            "end:  454\n",
            "end:  455\n",
            "end:  456\n",
            "end:  457\n",
            "end:  458\n",
            "end:  459\n",
            "end:  460\n",
            "end:  461\n",
            "end:  462\n",
            "end:  463\n",
            "end:  464\n",
            "end:  465\n",
            "end:  466\n",
            "end:  467\n",
            "end:  468\n",
            "end:  469\n",
            "end:  470\n",
            "end:  471\n",
            "end:  472\n",
            "end:  473\n",
            "end:  474\n",
            "end:  475\n",
            "end:  476\n",
            "end:  477\n",
            "end:  478\n",
            "end:  479\n",
            "end:  480\n",
            "end:  481\n",
            "end:  482\n",
            "end:  483\n",
            "end:  484\n",
            "end:  485\n",
            "end:  486\n",
            "end:  487\n",
            "end:  488\n",
            "end:  489\n",
            "end:  490\n",
            "end:  491\n",
            "end:  492\n",
            "end:  493\n",
            "end:  494\n",
            "end:  495\n",
            "end:  496\n",
            "end:  497\n",
            "end:  498\n",
            "end:  499\n",
            "end:  500\n",
            "end:  501\n",
            "end:  502\n",
            "end:  503\n",
            "end:  504\n",
            "end:  505\n",
            "end:  506\n",
            "end:  507\n",
            "end:  508\n",
            "end:  509\n",
            "end:  510\n",
            "end:  511\n",
            "end:  512\n",
            "end:  513\n",
            "end:  514\n",
            "end:  515\n",
            "end:  516\n",
            "end:  517\n",
            "end:  518\n",
            "end:  519\n",
            "end:  520\n",
            "end:  521\n",
            "end:  522\n",
            "end:  523\n",
            "end:  524\n",
            "end:  525\n",
            "end:  526\n",
            "end:  527\n",
            "end:  528\n",
            "end:  529\n",
            "end:  530\n",
            "end:  531\n",
            "end:  532\n",
            "end:  533\n",
            "end:  534\n",
            "end:  535\n",
            "end:  536\n",
            "end:  537\n",
            "end:  538\n",
            "end:  539\n",
            "end:  540\n",
            "end:  541\n",
            "end:  542\n",
            "end:  543\n",
            "end:  544\n",
            "end:  545\n",
            "end:  546\n",
            "end:  547\n",
            "end:  548\n",
            "end:  549\n",
            "end:  550\n",
            "end:  551\n",
            "end:  552\n",
            "end:  553\n",
            "end:  554\n",
            "end:  555\n",
            "end:  556\n",
            "end:  557\n",
            "end:  558\n",
            "end:  559\n",
            "end:  560\n",
            "end:  561\n",
            "end:  562\n",
            "end:  563\n",
            "end:  564\n",
            "end:  565\n",
            "end:  566\n",
            "end:  567\n",
            "end:  568\n",
            "end:  569\n",
            "end:  570\n",
            "end:  571\n",
            "end:  572\n",
            "end:  573\n",
            "end:  574\n",
            "end:  575\n",
            "end:  576\n",
            "end:  577\n",
            "end:  578\n",
            "end:  579\n",
            "end:  580\n",
            "end:  581\n",
            "end:  582\n",
            "end:  583\n",
            "end:  584\n",
            "end:  585\n",
            "end:  586\n",
            "end:  587\n",
            "end:  588\n",
            "end:  589\n",
            "end:  590\n",
            "end:  591\n",
            "end:  592\n",
            "end:  593\n",
            "end:  594\n",
            "end:  595\n",
            "end:  596\n",
            "end:  597\n",
            "end:  598\n",
            "end:  599\n",
            "end:  600\n",
            "end:  601\n",
            "end:  602\n",
            "end:  603\n",
            "end:  604\n",
            "end:  605\n",
            "end:  606\n",
            "end:  607\n",
            "end:  608\n",
            "end:  609\n",
            "end:  610\n",
            "end:  611\n",
            "end:  612\n",
            "end:  613\n",
            "end:  614\n",
            "end:  615\n",
            "end:  616\n",
            "end:  617\n",
            "end:  618\n",
            "end:  619\n",
            "end:  620\n",
            "end:  621\n",
            "end:  622\n",
            "end:  623\n",
            "end:  624\n",
            "end:  625\n",
            "end:  626\n",
            "end:  627\n",
            "end:  628\n",
            "end:  629\n",
            "end:  630\n",
            "end:  631\n",
            "end:  632\n",
            "end:  633\n",
            "end:  634\n",
            "end:  635\n",
            "end:  636\n",
            "end:  637\n",
            "end:  638\n",
            "end:  639\n",
            "end:  640\n",
            "end:  641\n",
            "end:  642\n",
            "end:  643\n",
            "end:  644\n",
            "end:  645\n",
            "end:  646\n",
            "end:  647\n",
            "end:  648\n",
            "end:  649\n",
            "end:  650\n",
            "end:  651\n",
            "end:  652\n",
            "end:  653\n",
            "end:  654\n",
            "end:  655\n",
            "end:  656\n",
            "end:  657\n",
            "end:  658\n",
            "end:  659\n",
            "end:  660\n",
            "end:  661\n",
            "end:  662\n",
            "end:  663\n",
            "end:  664\n",
            "end:  665\n",
            "end:  666\n",
            "end:  667\n",
            "end:  668\n",
            "end:  669\n",
            "end:  670\n",
            "end:  671\n",
            "end:  672\n",
            "end:  673\n",
            "end:  674\n",
            "end:  675\n",
            "end:  676\n",
            "end:  677\n",
            "end:  678\n",
            "end:  679\n",
            "end:  680\n",
            "end:  681\n",
            "end:  682\n",
            "end:  683\n",
            "end:  684\n",
            "end:  685\n",
            "end:  686\n",
            "end:  687\n",
            "end:  688\n",
            "end:  689\n",
            "end:  690\n",
            "end:  691\n",
            "end:  692\n",
            "end:  693\n",
            "end:  694\n",
            "end:  695\n",
            "end:  696\n",
            "end:  697\n",
            "end:  698\n",
            "end:  699\n",
            "end:  700\n",
            "end:  701\n",
            "end:  702\n",
            "end:  703\n",
            "end:  704\n",
            "end:  705\n",
            "end:  706\n",
            "end:  707\n",
            "end:  708\n",
            "end:  709\n",
            "end:  710\n",
            "end:  711\n",
            "end:  712\n",
            "end:  713\n",
            "end:  714\n",
            "end:  715\n",
            "end:  716\n",
            "end:  717\n",
            "end:  718\n",
            "end:  719\n",
            "end:  720\n",
            "end:  721\n",
            "end:  722\n",
            "end:  723\n",
            "end:  724\n",
            "end:  725\n",
            "end:  726\n",
            "end:  727\n",
            "end:  728\n",
            "end:  729\n",
            "end:  730\n",
            "end:  731\n",
            "end:  732\n",
            "end:  733\n",
            "end:  734\n",
            "end:  735\n",
            "end:  736\n",
            "end:  737\n",
            "end:  738\n",
            "end:  739\n",
            "end:  740\n",
            "end:  741\n",
            "end:  742\n",
            "end:  743\n",
            "end:  744\n",
            "end:  745\n",
            "end:  746\n",
            "end:  747\n",
            "end:  748\n",
            "end:  749\n",
            "end:  750\n",
            "end:  751\n",
            "end:  752\n",
            "end:  753\n",
            "end:  754\n",
            "end:  755\n",
            "end:  756\n",
            "end:  757\n",
            "end:  758\n",
            "end:  759\n",
            "end:  760\n",
            "end:  761\n",
            "end:  762\n",
            "end:  763\n",
            "end:  764\n",
            "end:  765\n",
            "end:  766\n",
            "end:  767\n",
            "end:  768\n",
            "end:  769\n",
            "end:  770\n",
            "end:  771\n",
            "end:  772\n",
            "end:  773\n",
            "end:  774\n",
            "end:  775\n",
            "end:  776\n",
            "end:  777\n",
            "end:  778\n",
            "end:  779\n",
            "end:  780\n",
            "end:  781\n",
            "end:  782\n",
            "end:  783\n",
            "end:  784\n",
            "end:  785\n",
            "end:  786\n",
            "end:  787\n",
            "end:  788\n",
            "end:  789\n",
            "end:  790\n",
            "end:  791\n",
            "end:  792\n",
            "end:  793\n",
            "end:  794\n",
            "end:  795\n",
            "end:  796\n",
            "end:  797\n",
            "end:  798\n",
            "end:  799\n",
            "end:  800\n",
            "end:  801\n",
            "end:  802\n",
            "end:  803\n",
            "end:  804\n",
            "end:  805\n",
            "end:  806\n",
            "end:  807\n",
            "end:  808\n",
            "end:  809\n",
            "end:  810\n",
            "end:  811\n",
            "end:  812\n",
            "end:  813\n",
            "end:  814\n",
            "end:  815\n",
            "end:  816\n",
            "end:  817\n",
            "end:  818\n",
            "end:  819\n",
            "end:  820\n",
            "end:  821\n",
            "end:  822\n",
            "end:  823\n",
            "end:  824\n",
            "end:  825\n",
            "end:  826\n",
            "end:  827\n",
            "end:  828\n",
            "end:  829\n",
            "end:  830\n",
            "end:  831\n",
            "end:  832\n",
            "end:  833\n",
            "end:  834\n",
            "end:  835\n",
            "end:  836\n",
            "end:  837\n",
            "end:  838\n",
            "end:  839\n",
            "end:  840\n",
            "end:  841\n",
            "end:  842\n",
            "end:  843\n",
            "end:  844\n",
            "end:  845\n",
            "end:  846\n",
            "end:  847\n",
            "end:  848\n",
            "end:  849\n",
            "end:  850\n",
            "end:  851\n",
            "end:  852\n",
            "end:  853\n",
            "end:  854\n",
            "end:  855\n",
            "end:  856\n",
            "end:  857\n",
            "end:  858\n",
            "end:  859\n",
            "end:  860\n",
            "end:  861\n",
            "end:  862\n",
            "end:  863\n",
            "end:  864\n",
            "end:  865\n",
            "end:  866\n",
            "end:  867\n",
            "end:  868\n",
            "end:  869\n",
            "end:  870\n",
            "end:  871\n",
            "end:  872\n",
            "end:  873\n",
            "end:  874\n",
            "end:  875\n",
            "end:  876\n",
            "end:  877\n",
            "end:  878\n",
            "end:  879\n",
            "end:  880\n",
            "end:  881\n",
            "end:  882\n",
            "end:  883\n",
            "end:  884\n",
            "end:  885\n",
            "end:  886\n",
            "end:  887\n",
            "end:  888\n",
            "end:  889\n",
            "end:  890\n",
            "end:  891\n",
            "end:  892\n",
            "end:  893\n",
            "end:  894\n",
            "end:  895\n",
            "end:  896\n",
            "end:  897\n",
            "end:  898\n",
            "end:  899\n",
            "end:  900\n",
            "end:  901\n",
            "end:  902\n",
            "end:  903\n",
            "end:  904\n",
            "end:  905\n",
            "end:  906\n",
            "end:  907\n",
            "end:  908\n",
            "end:  909\n",
            "end:  910\n",
            "end:  911\n",
            "end:  912\n",
            "end:  913\n",
            "end:  914\n",
            "end:  915\n",
            "end:  916\n",
            "end:  917\n",
            "end:  918\n",
            "end:  919\n",
            "end:  920\n",
            "end:  921\n",
            "end:  922\n",
            "end:  923\n",
            "end:  924\n",
            "end:  925\n",
            "end:  926\n",
            "end:  927\n",
            "end:  928\n",
            "end:  929\n",
            "end:  930\n",
            "end:  931\n",
            "end:  932\n",
            "end:  933\n",
            "end:  934\n",
            "end:  935\n",
            "end:  936\n",
            "end:  937\n",
            "end:  938\n",
            "end:  939\n",
            "end:  940\n",
            "end:  941\n",
            "end:  942\n",
            "end:  943\n",
            "end:  944\n",
            "end:  945\n",
            "end:  946\n",
            "end:  947\n",
            "end:  948\n",
            "end:  949\n",
            "end:  950\n",
            "end:  951\n",
            "end:  952\n",
            "end:  953\n",
            "end:  954\n",
            "end:  955\n",
            "end:  956\n",
            "end:  957\n",
            "end:  958\n",
            "end:  959\n",
            "end:  960\n",
            "end:  961\n",
            "end:  962\n",
            "end:  963\n",
            "end:  964\n",
            "end:  965\n",
            "end:  966\n",
            "end:  967\n",
            "end:  968\n",
            "end:  969\n",
            "end:  970\n",
            "end:  971\n",
            "end:  972\n",
            "end:  973\n",
            "end:  974\n",
            "end:  975\n",
            "end:  976\n",
            "end:  977\n",
            "end:  978\n",
            "end:  979\n",
            "end:  980\n",
            "end:  981\n",
            "end:  982\n",
            "end:  983\n",
            "end:  984\n",
            "end:  985\n",
            "end:  986\n",
            "end:  987\n",
            "end:  988\n",
            "end:  989\n",
            "end:  990\n",
            "end:  991\n",
            "end:  992\n",
            "end:  993\n",
            "end:  994\n",
            "end:  995\n",
            "end:  996\n",
            "end:  997\n",
            "end:  998\n",
            "end:  999\n",
            "end:  1000\n",
            "end:  1001\n",
            "end:  1002\n",
            "end:  1003\n",
            "end:  1004\n",
            "end:  1005\n",
            "end:  1006\n",
            "end:  1007\n",
            "end:  1008\n",
            "end:  1009\n",
            "end:  1010\n",
            "end:  1011\n",
            "end:  1012\n",
            "end:  1013\n",
            "end:  1014\n",
            "end:  1015\n",
            "end:  1016\n",
            "end:  1017\n",
            "end:  1018\n",
            "end:  1019\n",
            "end:  1020\n",
            "end:  1021\n",
            "end:  1022\n",
            "end:  1023\n",
            "end:  1024\n",
            "end:  1025\n",
            "end:  1026\n",
            "end:  1027\n",
            "end:  1028\n",
            "end:  1029\n",
            "end:  1030\n",
            "end:  1031\n",
            "end:  1032\n",
            "end:  1033\n",
            "end:  1034\n",
            "end:  1035\n",
            "end:  1036\n",
            "end:  1037\n",
            "end:  1038\n",
            "end:  1039\n",
            "end:  1040\n",
            "end:  1041\n",
            "end:  1042\n",
            "end:  1043\n",
            "end:  1044\n",
            "end:  1045\n",
            "end:  1046\n",
            "end:  1047\n",
            "end:  1048\n",
            "end:  1049\n",
            "end:  1050\n",
            "end:  1051\n",
            "end:  1052\n",
            "end:  1053\n",
            "end:  1054\n",
            "end:  1055\n",
            "end:  1056\n",
            "end:  1057\n",
            "end:  1058\n",
            "end:  1059\n",
            "end:  1060\n",
            "end:  1061\n",
            "end:  1062\n",
            "end:  1063\n",
            "end:  1064\n",
            "end:  1065\n",
            "end:  1066\n",
            "end:  1067\n",
            "end:  1068\n",
            "end:  1069\n",
            "end:  1070\n",
            "end:  1071\n",
            "end:  1072\n",
            "end:  1073\n",
            "end:  1074\n",
            "end:  1075\n",
            "end:  1076\n",
            "end:  1077\n",
            "end:  1078\n",
            "end:  1079\n",
            "end:  1080\n",
            "end:  1081\n",
            "end:  1082\n",
            "end:  1083\n",
            "end:  1084\n",
            "end:  1085\n",
            "end:  1086\n",
            "end:  1087\n",
            "end:  1088\n",
            "end:  1089\n",
            "end:  1090\n",
            "end:  1091\n",
            "end:  1092\n",
            "end:  1093\n",
            "end:  1094\n",
            "end:  1095\n",
            "end:  1096\n",
            "end:  1097\n",
            "end:  1098\n",
            "end:  1099\n",
            "end:  1100\n",
            "end:  1101\n",
            "end:  1102\n",
            "end:  1103\n",
            "end:  1104\n",
            "end:  1105\n",
            "end:  1106\n",
            "end:  1107\n",
            "end:  1108\n",
            "end:  1109\n",
            "end:  1110\n",
            "end:  1111\n",
            "end:  1112\n",
            "end:  1113\n",
            "end:  1114\n",
            "end:  1115\n",
            "end:  1116\n",
            "end:  1117\n",
            "end:  1118\n",
            "end:  1119\n",
            "end:  1120\n",
            "end:  1121\n",
            "end:  1122\n",
            "end:  1123\n",
            "end:  1124\n",
            "end:  1125\n",
            "end:  1126\n",
            "end:  1127\n",
            "end:  1128\n",
            "end:  1129\n",
            "end:  1130\n",
            "end:  1131\n",
            "end:  1132\n",
            "end:  1133\n",
            "end:  1134\n",
            "end:  1135\n",
            "end:  1136\n",
            "end:  1137\n",
            "end:  1138\n",
            "end:  1139\n",
            "end:  1140\n",
            "end:  1141\n",
            "end:  1142\n",
            "end:  1143\n",
            "end:  1144\n",
            "end:  1145\n",
            "end:  1146\n",
            "end:  1147\n",
            "end:  1148\n",
            "end:  1149\n",
            "end:  1150\n",
            "end:  1151\n",
            "end:  1152\n",
            "end:  1153\n",
            "end:  1154\n",
            "end:  1155\n",
            "end:  1156\n",
            "end:  1157\n",
            "end:  1158\n",
            "end:  1159\n",
            "end:  1160\n",
            "end:  1161\n",
            "end:  1162\n",
            "end:  1163\n",
            "end:  1164\n",
            "end:  1165\n",
            "end:  1166\n",
            "end:  1167\n",
            "end:  1168\n",
            "end:  1169\n",
            "end:  1170\n",
            "end:  1171\n",
            "end:  1172\n",
            "end:  1173\n",
            "end:  1174\n",
            "end:  1175\n",
            "end:  1176\n",
            "end:  1177\n",
            "end:  1178\n",
            "end:  1179\n",
            "end:  1180\n",
            "end:  1181\n",
            "end:  1182\n",
            "end:  1183\n",
            "end:  1184\n",
            "end:  1185\n",
            "end:  1186\n",
            "end:  1187\n",
            "end:  1188\n",
            "end:  1189\n",
            "end:  1190\n",
            "end:  1191\n",
            "end:  1192\n",
            "end:  1193\n",
            "end:  1194\n",
            "end:  1195\n",
            "end:  1196\n",
            "end:  1197\n",
            "end:  1198\n",
            "end:  1199\n",
            "end:  1200\n",
            "end:  1201\n",
            "end:  1202\n",
            "end:  1203\n",
            "end:  1204\n",
            "end:  1205\n",
            "end:  1206\n",
            "end:  1207\n",
            "end:  1208\n",
            "end:  1209\n",
            "end:  1210\n",
            "end:  1211\n",
            "end:  1212\n",
            "end:  1213\n",
            "end:  1214\n",
            "end:  1215\n",
            "end:  1216\n",
            "end:  1217\n",
            "end:  1218\n",
            "end:  1219\n",
            "end:  1220\n",
            "end:  1221\n",
            "end:  1222\n",
            "end:  1223\n",
            "end:  1224\n",
            "end:  1225\n",
            "end:  1226\n",
            "end:  1227\n",
            "end:  1228\n",
            "end:  1229\n",
            "end:  1230\n",
            "end:  1231\n",
            "end:  1232\n",
            "end:  1233\n",
            "end:  1234\n",
            "end:  1235\n",
            "end:  1236\n",
            "end:  1237\n",
            "end:  1238\n",
            "end:  1239\n",
            "end:  1240\n",
            "end:  1241\n",
            "end:  1242\n",
            "end:  1243\n",
            "end:  1244\n",
            "end:  1245\n",
            "end:  1246\n",
            "end:  1247\n",
            "end:  1248\n",
            "end:  1249\n",
            "end:  1250\n",
            "end:  1251\n",
            "end:  1252\n",
            "end:  1253\n",
            "end:  1254\n",
            "end:  1255\n",
            "end:  1256\n",
            "end:  1257\n",
            "end:  1258\n",
            "end:  1259\n",
            "end:  1260\n",
            "end:  1261\n",
            "end:  1262\n",
            "end:  1263\n",
            "end:  1264\n",
            "end:  1265\n",
            "end:  1266\n",
            "end:  1267\n",
            "end:  1268\n",
            "end:  1269\n",
            "end:  1270\n",
            "end:  1271\n",
            "end:  1272\n",
            "end:  1273\n",
            "end:  1274\n",
            "end:  1275\n",
            "end:  1276\n",
            "end:  1277\n",
            "end:  1278\n",
            "end:  1279\n",
            "end:  1280\n",
            "end:  1281\n",
            "end:  1282\n",
            "end:  1283\n",
            "end:  1284\n",
            "end:  1285\n",
            "end:  1286\n",
            "end:  1287\n",
            "end:  1288\n",
            "end:  1289\n",
            "end:  1290\n",
            "end:  1291\n",
            "end:  1292\n",
            "end:  1293\n",
            "end:  1294\n",
            "end:  1295\n",
            "end:  1296\n",
            "end:  1297\n",
            "end:  1298\n",
            "end:  1299\n",
            "end:  1300\n",
            "end:  1301\n",
            "end:  1302\n",
            "end:  1303\n",
            "end:  1304\n",
            "end:  1305\n",
            "end:  1306\n",
            "end:  1307\n",
            "end:  1308\n",
            "end:  1309\n",
            "end:  1310\n",
            "end:  1311\n",
            "end:  1312\n",
            "end:  1313\n",
            "end:  1314\n",
            "end:  1315\n",
            "end:  1316\n",
            "end:  1317\n",
            "end:  1318\n",
            "end:  1319\n",
            "end:  1320\n",
            "end:  1321\n",
            "end:  1322\n",
            "end:  1323\n",
            "end:  1324\n",
            "end:  1325\n",
            "end:  1326\n",
            "end:  1327\n",
            "end:  1328\n",
            "end:  1329\n",
            "end:  1330\n",
            "end:  1331\n",
            "end:  1332\n",
            "end:  1333\n",
            "end:  1334\n",
            "end:  1335\n",
            "end:  1336\n",
            "end:  1337\n",
            "end:  1338\n",
            "end:  1339\n",
            "end:  1340\n",
            "end:  1341\n",
            "end:  1342\n",
            "end:  1343\n",
            "end:  1344\n",
            "end:  1345\n",
            "end:  1346\n",
            "end:  1347\n",
            "end:  1348\n",
            "end:  1349\n",
            "end:  1350\n",
            "end:  1351\n",
            "end:  1352\n",
            "end:  1353\n",
            "end:  1354\n",
            "end:  1355\n",
            "end:  1356\n",
            "end:  1357\n",
            "end:  1358\n",
            "end:  1359\n",
            "end:  1360\n",
            "end:  1361\n",
            "end:  1362\n",
            "end:  1363\n",
            "end:  1364\n",
            "end:  1365\n",
            "end:  1366\n",
            "end:  1367\n",
            "end:  1368\n",
            "end:  1369\n",
            "end:  1370\n",
            "end:  1371\n",
            "end:  1372\n",
            "end:  1373\n",
            "end:  1374\n",
            "end:  1375\n",
            "end:  1376\n",
            "end:  1377\n",
            "end:  1378\n",
            "end:  1379\n",
            "end:  1380\n",
            "end:  1381\n",
            "end:  1382\n",
            "end:  1383\n",
            "end:  1384\n",
            "end:  1385\n",
            "end:  1386\n",
            "end:  1387\n",
            "end:  1388\n",
            "end:  1389\n",
            "end:  1390\n",
            "end:  1391\n",
            "end:  1392\n",
            "end:  1393\n",
            "end:  1394\n",
            "end:  1395\n",
            "end:  1396\n",
            "end:  1397\n",
            "end:  1398\n",
            "end:  1399\n",
            "end:  1400\n",
            "end:  1401\n",
            "end:  1402\n",
            "end:  1403\n",
            "end:  1404\n",
            "end:  1405\n",
            "end:  1406\n",
            "end:  1407\n",
            "end:  1408\n",
            "end:  1409\n",
            "end:  1410\n",
            "end:  1411\n",
            "end:  1412\n",
            "end:  1413\n",
            "end:  1414\n",
            "end:  1415\n",
            "end:  1416\n",
            "end:  1417\n",
            "end:  1418\n",
            "end:  1419\n",
            "end:  1420\n",
            "end:  1421\n",
            "end:  1422\n",
            "end:  1423\n",
            "end:  1424\n",
            "end:  1425\n",
            "end:  1426\n",
            "end:  1427\n",
            "end:  1428\n",
            "end:  1429\n",
            "end:  1430\n",
            "end:  1431\n",
            "end:  1432\n",
            "end:  1433\n",
            "end:  1434\n",
            "end:  1435\n",
            "end:  1436\n",
            "end:  1437\n",
            "end:  1438\n",
            "end:  1439\n",
            "end:  1440\n",
            "end:  1441\n",
            "end:  1442\n",
            "end:  1443\n",
            "end:  1444\n",
            "end:  1445\n",
            "end:  1446\n",
            "end:  1447\n",
            "end:  1448\n",
            "end:  1449\n",
            "end:  1450\n",
            "end:  1451\n",
            "end:  1452\n",
            "end:  1453\n",
            "end:  1454\n",
            "end:  1455\n",
            "end:  1456\n",
            "end:  1457\n",
            "end:  1458\n",
            "end:  1459\n",
            "end:  1460\n",
            "end:  1461\n",
            "end:  1462\n",
            "end:  1463\n",
            "end:  1464\n",
            "end:  1465\n",
            "end:  1466\n",
            "end:  1467\n",
            "end:  1468\n",
            "end:  1469\n",
            "end:  1470\n",
            "end:  1471\n",
            "end:  1472\n",
            "end:  1473\n",
            "end:  1474\n",
            "end:  1475\n",
            "end:  1476\n",
            "end:  1477\n",
            "end:  1478\n",
            "end:  1479\n",
            "end:  1480\n",
            "end:  1481\n",
            "end:  1482\n",
            "end:  1483\n",
            "end:  1484\n",
            "end:  1485\n",
            "end:  1486\n",
            "end:  1487\n",
            "end:  1488\n",
            "end:  1489\n",
            "end:  1490\n",
            "end:  1491\n",
            "end:  1492\n",
            "end:  1493\n",
            "end:  1494\n",
            "end:  1495\n",
            "end:  1496\n",
            "end:  1497\n",
            "end:  1498\n",
            "end:  1499\n",
            "end:  1500\n",
            "end:  1501\n",
            "end:  1502\n",
            "end:  1503\n",
            "end:  1504\n",
            "end:  1505\n",
            "end:  1506\n",
            "end:  1507\n",
            "end:  1508\n",
            "end:  1509\n",
            "end:  1510\n",
            "end:  1511\n",
            "end:  1512\n",
            "end:  1513\n",
            "end:  1514\n",
            "end:  1515\n",
            "end:  1516\n",
            "end:  1517\n",
            "end:  1518\n",
            "end:  1519\n",
            "end:  1520\n",
            "end:  1521\n",
            "end:  1522\n",
            "end:  1523\n",
            "end:  1524\n",
            "end:  1525\n",
            "end:  1526\n",
            "end:  1527\n",
            "end:  1528\n",
            "end:  1529\n",
            "end:  1530\n",
            "end:  1531\n",
            "end:  1532\n",
            "end:  1533\n",
            "end:  1534\n",
            "end:  1535\n",
            "end:  1536\n",
            "end:  1537\n",
            "end:  1538\n",
            "end:  1539\n",
            "end:  1540\n",
            "end:  1541\n",
            "end:  1542\n",
            "end:  1543\n",
            "end:  1544\n",
            "end:  1545\n",
            "end:  1546\n",
            "end:  1547\n",
            "end:  1548\n",
            "end:  1549\n",
            "end:  1550\n",
            "end:  1551\n",
            "end:  1552\n",
            "end:  1553\n",
            "end:  1554\n",
            "end:  1555\n",
            "end:  1556\n",
            "end:  1557\n",
            "end:  1558\n",
            "end:  1559\n",
            "end:  1560\n",
            "end:  1561\n",
            "end:  1562\n",
            "end:  1563\n",
            "end:  1564\n",
            "end:  1565\n",
            "end:  1566\n",
            "end:  1567\n",
            "end:  1568\n",
            "end:  1569\n",
            "end:  1570\n",
            "end:  1571\n",
            "end:  1572\n",
            "end:  1573\n",
            "end:  1574\n",
            "end:  1575\n",
            "end:  1576\n",
            "end:  1577\n",
            "end:  1578\n",
            "end:  1579\n",
            "end:  1580\n",
            "end:  1581\n",
            "end:  1582\n",
            "end:  1583\n",
            "end:  1584\n",
            "end:  1585\n",
            "end:  1586\n",
            "end:  1587\n",
            "end:  1588\n",
            "end:  1589\n",
            "end:  1590\n",
            "end:  1591\n",
            "end:  1592\n",
            "end:  1593\n",
            "end:  1594\n",
            "end:  1595\n",
            "end:  1596\n",
            "end:  1597\n",
            "end:  1598\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-36e35ce2de8e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1563\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;31m# Mask heads if we want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 14.75 GiB total capacity; 13.33 GiB already allocated; 182.81 MiB free; 13.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "num_epoch = 0\n",
        "num_batch = 0\n",
        "for epoch in range(1):  # Adjust the number of training epochs as needed\n",
        "    model.train()\n",
        "    num_batch = 0\n",
        "    for batch in train_loader:\n",
        "        \n",
        "        try:\n",
        "          inputs = tokenizer(batch['text'], padding=True, truncation=True, return_tensors='pt')\n",
        "        except:\n",
        "          print(batch['text'])\n",
        "          print(\"error length:   \", len(batch['text']))\n",
        "\n",
        "        #inputs = tokenizer(batch['text'], padding=True, truncation=True, return_tensors='pt')\n",
        "    \n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        labels = batch['sentiment'].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**inputs)\n",
        "        #print(labels)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        \n",
        "        optimizer.step()\n",
        "        print(\"end: \", num_batch)\n",
        "        num_batch += 1\n",
        "        \n",
        "# Step 6: Evaluation\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = tokenizer(batch['text'], padding=True, truncation=True, return_tensors='pt')\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        labels = batch['sentiment'].to(device)\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "\n",
        "        true_labels.extend(labels.tolist())\n",
        "        predicted_labels.extend(predicted.tolist())\n",
        "\n",
        "classification_rep = classification_report(true_labels, predicted_labels)\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader[140]"
      ],
      "metadata": {
        "id": "fpBBqSEcIiDF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}