{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, PorterStemmer\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import gensim\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import nltk\n",
    "import warnings\n",
    "# from keras import backend as K\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.6.2-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/zhumingjia/opt/anaconda3/lib/python3.7/site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /Users/zhumingjia/opt/anaconda3/lib/python3.7/site-packages (from xgboost) (1.5.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/zhumingjia/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804869</th>\n",
       "      <td>0</td>\n",
       "      <td>Maybe the tax on \"things\" would be collected w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804870</th>\n",
       "      <td>0</td>\n",
       "      <td>What do you call people who STILL think the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804871</th>\n",
       "      <td>0</td>\n",
       "      <td>thank you ,,,right or wrong,,, i am following ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804872</th>\n",
       "      <td>1</td>\n",
       "      <td>Anyone who is quoted as having the following e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804873</th>\n",
       "      <td>0</td>\n",
       "      <td>Students defined as EBD are legally just as di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1804874 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                       comment_text\n",
       "0             0  This is so cool. It's like, 'would you want yo...\n",
       "1             0  Thank you!! This would make my life a lot less...\n",
       "2             0  This is such an urgent design problem; kudos t...\n",
       "3             0  Is this something I'll be able to install on m...\n",
       "4             1               haha you guys are a bunch of losers.\n",
       "...         ...                                                ...\n",
       "1804869       0  Maybe the tax on \"things\" would be collected w...\n",
       "1804870       0  What do you call people who STILL think the di...\n",
       "1804871       0  thank you ,,,right or wrong,,, i am following ...\n",
       "1804872       1  Anyone who is quoted as having the following e...\n",
       "1804873       0  Students defined as EBD are legally just as di...\n",
       "\n",
       "[1804874 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('toxic_classification.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess(text_string):\n",
    "    text_string = text_string.lower() \n",
    "    text_string = re.sub('[^A-Za-z0-9]+', ' ', text_string) \n",
    "    \n",
    "    x = text_string.split()\n",
    "    new_text = []\n",
    "    \n",
    "    for word in x:\n",
    "        if word not in stop_words:\n",
    "            new_text.append(stemmer.stem(word))\n",
    "            \n",
    "    text_string = ' '.join(new_text)\n",
    "    return text_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_text'] = df['comment_text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.read_csv('toxic_classification_preprocessed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['target'] == 0].iloc[:20000, :]\n",
    "df_1 = df[df['target'] == 1].iloc[:20000, :]\n",
    "df_small = pd.concat([df_0, df_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_small['preprocessed_text'], df_small['target'], test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30123"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = list(df_small['preprocessed_text'])\n",
    "vocab_set = set()\n",
    "tokenizer = nltk.tokenize.word_tokenize\n",
    "\n",
    "for sample in dataset:\n",
    "    words = tokenizer(sample)\n",
    "    vocab_set.update(words)\n",
    "\n",
    "# Number of unique words\n",
    "num_unique_words = len(vocab_set)\n",
    "num_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_length = [len(i.split(\" \")) for i in dataset]\n",
    "max(list_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters of the model\n",
    "vocab_size = 30123 # choose based on statistics\n",
    "oov_tok = ''\n",
    "embedding_dim = 100\n",
    "max_length = 221 # choose based on statistics, for example 150 to 200\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "# tokenize sentences\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "# convert train dataset to sequence and pad sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "# convert Test dataset to sequence and pad sequences\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 221, 100)          3012300   \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 24)                3096      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 3,099,901\n",
      "Trainable params: 3,099,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "900/900 [==============================] - 78s 83ms/step - loss: 0.5072 - accuracy: 0.7363 - val_loss: 0.3011 - val_accuracy: 0.8778\n",
      "Epoch 2/2\n",
      "900/900 [==============================] - 72s 80ms/step - loss: 0.2030 - accuracy: 0.9232 - val_loss: 0.2944 - val_accuracy: 0.8794\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "history = model.fit(train_padded, y_train, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.1)\n",
    "\n",
    "prediction = model.predict(test_padded)\n",
    "# Get labels based on probability 1 if p>= 0.5 else 0\n",
    "pred_labels = []\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "#print(\"Accuracy of prediction on test set : \", accuracy_score(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8881859106947316"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "f1_score(y_test,pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8643144683874023"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9134134134134134"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_indices = X_train.index\n",
    "test_indices = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_idx_fp = []\n",
    "wrong_idx_fn = []\n",
    "y_test_list = list(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    if y_test_list[i] != pred_labels[i]:\n",
    "        if pred_labels[i] == 1:\n",
    "            wrong_idx_fp.append(i)\n",
    "        else:\n",
    "            wrong_idx_fn.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong_idx_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong_idx_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = list(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(idx):\n",
    "    t = test_text[wrong_idx_fp[idx]]\n",
    "    print(t)\n",
    "    print(\"=========\")\n",
    "    pre_t = list(df_small[df_small['preprocessed_text'] == t]['comment_text'])[0]\n",
    "    print(pre_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_fn(idx):\n",
    "    t = test_text[wrong_idx_fn[idx]]\n",
    "    print(t)\n",
    "    print(\"=========\")\n",
    "    pre_t = list(df_small[df_small['preprocessed_text'] == t]['comment_text'])[0]\n",
    "    print(pre_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vote lesser two evil life sick find attitud voter refus vote lesser two evil unsophist except condescend one might counter say continu support two parti system altern either dupe part dupe class suspect republican parti fractur soon three candid year trump clinton sander republican question one third parti candid\n",
      "=========\n",
      "I have been voting for the lesser of two evils for most of my life, and I am sick of it.\n",
      "\n",
      "I find your attitude that voters who refuse to vote for the lesser of two evils as \"unsophisticated\" to be exceptionally condescending.  One might counter by saying those who continue to support the two-party system over all other alternatives are either being duped, or are part of the duping class.\n",
      "\n",
      " I suspect the Republican party will fracture soon and we will have three candidates this year: Trump, Clinton or Sanders, and a Republican. The question is, which one is the third-party candidate?\n"
     ]
    }
   ],
   "source": [
    "get_text(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phil Knight, his Nike-rich buddies, and sycophants such as our esteemed legislators, will tell you what is \"best for you.\"  Follow their \"lead\", stay out of their way, get \"behind\" them  and, if you're lucky, a few bucks might fall out of their pockets for you to grovel for.  \n",
      "\n",
      "Face it, the very wealthy know \"what is best\".......for them.....you don't really count.  They tell us to    support an elite IAAF meet which will disrupt the University.....those damn students are just \"in the way\"; will cost over ten million dollars per day; will financially benefit only a very few individuals (those who don't really need the money); will have prohibitive ticket prices (so mere peasants can't attend); and will cost about 25 million in tax dollars.....gosh, how could we possibly turn that down??? \n",
      "\n",
      "In my opinion, our local Democatic legislators have, once again,  \"sold out\" to the wealthy special interest groups.  I've been an active Democrat for over fifty years and find your actions sad...\n"
     ]
    }
   ],
   "source": [
    "get_text(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be more supportive of Miss Loretta if she'd said \"why are there more Blacks in the system in the first place?\" And \"the frequency of the use of force in our jails is unacceptable no matter what color offenders' skin is\". \n",
      "\n",
      "Instead it sounds like the Oscars; everyone talkin bout boycotting due to the lack of \"diversity\" and honoring more \"people of color\", when really they're advocating only for Blacks only, not Hispanics/Latinos, or Asians, or Natives, who are the more discriminated against by far.\n"
     ]
    }
   ],
   "source": [
    "get_text(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good point, but still had nothing to do with liberals or liberalism.\n"
     ]
    }
   ],
   "source": [
    "get_text(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everi bit boast self righteous obama\n",
      "=========\n",
      "He's every bit as boastful and self righteous as Obama!\n"
     ]
    }
   ],
   "source": [
    "get_text_fn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would burn hous ground\n",
      "=========\n",
      "I would have burned the house to the ground.\n"
     ]
    }
   ],
   "source": [
    "get_text_fn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict pedant\n",
      "=========\n",
      "You are so predictable and pedantic.\n"
     ]
    }
   ],
   "source": [
    "get_text_fn(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
