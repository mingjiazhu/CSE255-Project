{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "686fae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade540d",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5954aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>cool like would want mother read realli great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>thank would make life lot less anxieti induc k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>urgent design problem kudo take impress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>someth abl instal site releas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>haha guy bunch loser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  target                                       comment_text  \\\n",
       "0           0       0  This is so cool. It's like, 'would you want yo...   \n",
       "1           1       0  Thank you!! This would make my life a lot less...   \n",
       "2           2       0  This is such an urgent design problem; kudos t...   \n",
       "3           3       0  Is this something I'll be able to install on m...   \n",
       "4           4       1               haha you guys are a bunch of losers.   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  cool like would want mother read realli great ...  \n",
       "1  thank would make life lot less anxieti induc k...  \n",
       "2            urgent design problem kudo take impress  \n",
       "3                      someth abl instal site releas  \n",
       "4                               haha guy bunch loser  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('toxic_classification.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6b4fb",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b022b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, PorterStemmer\n",
    "import re\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess(text_string):\n",
    "    text_string = text_string.lower() \n",
    "    text_string = re.sub('[^A-Za-z0-9]+', ' ', text_string) \n",
    "    \n",
    "    x = text_string.split()\n",
    "    new_text = []\n",
    "    \n",
    "    for word in x:\n",
    "        if word not in stop_words:\n",
    "            new_text.append(stemmer.stem(word))\n",
    "            \n",
    "    text_string = ' '.join(new_text)\n",
    "    return text_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95357f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cool like would want mother read realli great idea well done',\n",
       " 'thank would make life lot less anxieti induc keep let anyon get way',\n",
       " 'urgent design problem kudo take impress',\n",
       " 'someth abl instal site releas',\n",
       " 'haha guy bunch loser']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = []\n",
    "for index, value in df['comment_text'].items():\n",
    "    bag_of_words.append(preprocess(value))\n",
    "bag_of_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69f66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df):\n",
    "    labels = df['target']\n",
    "    zero_indices = []\n",
    "    one_indices = []\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == 0:\n",
    "            zero_indices.append(i)\n",
    "        else:\n",
    "            one_indices.append(i)\n",
    "    label_0 = random.sample(zero_indices, k=20000)\n",
    "    label_1 = random.sample(one_indices, k=20000)\n",
    "    labels = [0] * 20000 + [1] * 20000\n",
    "    bag_of_words_select = []\n",
    "    for i in label_0:\n",
    "        bag_of_words_select.append(bag_of_words[i])\n",
    "    for i in label_1:\n",
    "        bag_of_words_select.append(bag_of_words[i])\n",
    "    return labels, bag_of_words_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30059506",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, bag_of_words= sample_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df712912",
   "metadata": {},
   "source": [
    "# Bag-Of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76428bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(bag_of_words)\n",
    "X = vectorizer.transform(bag_of_words)\n",
    "X_train, X_test, y_train, y_test, text_train, text_test = train_test_split(X, labels, bag_of_words, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f720e485",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b6b46f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;max_iter&#x27;: [1000, 2000]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;max_iter&#x27;: [1000, 2000]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'max_iter': [1000, 2000]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "param_grid = {'max_iter': [1000, 2000], 'C': [0.1, 1, 10]}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e4b4b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 1, 'max_iter': 1000}, 0.8303664209272726)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_params,best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "440a9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a15a53",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fab971c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8268505268635359, 0.8610132755350853, 0.7952952952952953)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1d269e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_idx_fp = []\n",
    "wrong_idx_fn = []\n",
    "y_test_list = list(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    if y_test_list[i] != y_pred[i]:\n",
    "        if y_pred[i] == 1:\n",
    "            wrong_idx_fp.append(i)\n",
    "        else:\n",
    "            wrong_idx_fn.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713e376",
   "metadata": {},
   "source": [
    "### False Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6cdd3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_fp = random.sample(wrong_idx_fp, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f453c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then you react with a very dishonest reply! \"The Fort and Red Rocks\"? That was absurd and way out of context.\n",
      "-------------------------------\n",
      "react dishonest repli fort red rock absurd way context\n"
     ]
    }
   ],
   "source": [
    "text = text_test[random_sample_fp[0]]\n",
    "print(list(df[df['preprocessed_text'] == text]['comment_text'])[0])\n",
    "print(\"-------------------------------\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "52d6bb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is eating bannock racist?\n",
      "-------------------------------\n",
      "eat bannock racist\n"
     ]
    }
   ],
   "source": [
    "text = text_test[random_sample_fp[1]]\n",
    "print(list(df[df['preprocessed_text'] == text]['comment_text'])[0])\n",
    "print(\"-------------------------------\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c2f5552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"... a whole hour and not a single troll has shown up.\"\n",
      "\n",
      "Look again. Turns out you beat the patron saint of trolldom by six minutes. Apparently it's a working holiday for him.\n",
      "-------------------------------\n",
      "whole hour singl troll shown look turn beat patron saint trolldom six minut appar work holiday\n"
     ]
    }
   ],
   "source": [
    "text = text_test[random_sample_fp[2]]\n",
    "print(list(df[df['preprocessed_text'] == text]['comment_text'])[0])\n",
    "print(\"-------------------------------\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae22cf",
   "metadata": {},
   "source": [
    "### False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f2dcaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_fn = random.sample(wrong_idx_fn, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c142ffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump has always been a complete failure as a \"business guy\". Everything he touches files for bankruptcy. he couldn't even make a profit running six casinos!\n",
      "\n",
      "think before you post!\n",
      "-------------------------------\n",
      "trump alway complet failur busi guy everyth touch file bankruptci even make profit run six casino think post\n"
     ]
    }
   ],
   "source": [
    "text = text_test[random_sample_fn[0]]\n",
    "print(list(df[df['preprocessed_text'] == text]['comment_text'])[0])\n",
    "print(\"-------------------------------\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ee8cb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for nothing and don't let the door hit your fanny! Might get oil on it. The door, that is.\n",
      "-------------------------------\n",
      "thank noth let door hit fanni might get oil door\n"
     ]
    }
   ],
   "source": [
    "text = text_test[random_sample_fn[1]]\n",
    "print(list(df[df['preprocessed_text'] == text]['comment_text'])[0])\n",
    "print(\"-------------------------------\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d284d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, Black folks, be on the lookout for a ban on malt liquor 40's next...brought to you by your own party!\n",
      "-------------------------------\n",
      "hey black folk lookout ban malt liquor 40 next brought parti\n"
     ]
    }
   ],
   "source": [
    "text = text_test[random_sample_fn[2]]\n",
    "print(list(df[df['preprocessed_text'] == text]['comment_text'])[0])\n",
    "print(\"-------------------------------\")\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
