# CSE256-Project

In this project, we are going to work on toxicity classification. Our task will be to classify a comment as toxic or not toxic. This problem is interesting because it involves machine learning and AI models to perform sentiment analysis, deepening our understanding of how language is used in online interactions. Toxicity classification is important because it helps to promote online safety, enhance user experience, and protect vulnerable individuals.

We develop four methods to conduct toxicity classification with comments on the Civil Comments platform, including one baseline method and three advanced methods, including bag-of-words + logistic regression, word2vec + SVM, LSTM, and BERT. 

Dataset: https://drive.google.com/file/d/1EkW5bSoENLF9kqZLc1zrcIQbwmdHfH4w/view?usp=sharing
